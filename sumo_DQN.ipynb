{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyvirtualdisplay in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (10.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyvirtualdisplay Pillow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUMO Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMO_HOME is set to: C:\\Program Files (x86)\\Eclipse\\Sumo\n",
      "Does SUMO_HOME exist? True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from gymnasium import spaces\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "SUMO_HOME = 'C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo'\n",
    "\n",
    "os.environ['SUMO_HOME'] = SUMO_HOME\n",
    "\n",
    "# Print the SUMO_HOME environment variable to verify\n",
    "print(\"SUMO_HOME is set to:\", os.environ.get('SUMO_HOME'))\n",
    "\n",
    "# Check if the SUMO_HOME path exists\n",
    "print(\"Does SUMO_HOME exist?\", os.path.exists(os.environ.get('SUMO_HOME')))\n",
    "\n",
    "\n",
    "# Define file paths\n",
    "net_file = 'C:/Users/ASUS/Sumo/2024-11-03-18-23-47/osm.net.xml/osm.net.xml'\n",
    "route_file = 'C:/Users/ASUS/Sumo/2024-11-03-18-23-47/osm.passenger.rou.xml'\n",
    "out_csv_name = 'C:/Users/ASUS/Sumo/2024-11-03-18-23-47/osm.passenger.csv'\n",
    "config_file = 'C:/Users/ASUS/Sumo/2024-11-03-18-23-47/osm.sumocfg'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import sumo_rl\n",
    "import traci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self, env_name, route_file, net_file, out_csv_name, render_mode='human', num_seconds=100000, max_steps=1000, port=8873):\n",
    "        self.env_name = env_name\n",
    "        self.use_gui = True if render_mode == 'human' else False\n",
    "        self.route_file = route_file\n",
    "        self.net_file = net_file\n",
    "        self.out_csv_name = out_csv_name\n",
    "        self.env = gym.make(\n",
    "                        env_name,\n",
    "                        net_file=net_file,\n",
    "                        route_file=route_file,\n",
    "                        out_csv_name=out_csv_name,\n",
    "                        use_gui=self.use_gui,\n",
    "                        num_seconds=num_seconds\n",
    "                    )\n",
    "     \n",
    "        self.state, _ = self.env.reset()\n",
    "        self.done = False\n",
    "        self.observation_space = self.env.observation_space.shape[0]\n",
    "        self.action_space = self.env.action_space\n",
    "        self.traffic_signals = self.env.traffic_signals\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state, _ = self.env.reset()\n",
    "        self.done = False\n",
    "        return self.state\n",
    "    \n",
    "    def custom_reward(self, traffic_signal, reward_type='average_speed', reward_method='simple'):\n",
    "        if reward_method == 'simple':\n",
    "            match reward_type:\n",
    "                case 'average_speed':\n",
    "                    return traffic_signal.get_avgerage_speed()\n",
    "                case 'congesion':\n",
    "                    return -1 * traffic_signal.get_pressure()\n",
    "                case 'emissions':\n",
    "                    return -1* traffic_signal.get_emission_co2()\n",
    "                case 'throughput':\n",
    "                    return traffic_signal.get_throughput()\n",
    "\n",
    "        else:\n",
    "            # Weighted sum of the metrics\n",
    "            reward = 0\n",
    "            if weights is None:\n",
    "                weights = {\n",
    "                    'average_speed': 0.4,\n",
    "                    'waiting_time': 0.3,\n",
    "                    'emissions': 0.2,\n",
    "                    'throughput': 0.1\n",
    "                }\n",
    "\n",
    "            # Calculate individual rewards\n",
    "            average_speed = traffic_signal.get_average_speed()\n",
    "            waiting_time = -1* traffic_signal._diff_waiting_time_reward()\n",
    "            total_queue = -1 * traffic_signal.get_total_queued()\n",
    "            congesion = traffic_signal.get_pressure()\n",
    "\n",
    "            print(average_speed, waiting_time, total_queue, congesion)\n",
    "            weighted_reward = (\n",
    "                weights['average_speed'] * average_speed +\n",
    "                weights['waiting_time'] * waiting_time +\n",
    "                weights['emissions'] * total_queue +\n",
    "                weights['throughput'] * congesion\n",
    "            )\n",
    "\n",
    "            return weighted_reward\n",
    "            \n",
    "            \n",
    "    def step(self, action):\n",
    "        next_state, _, terminated, truncated, info = self.env.step(action)\n",
    "\n",
    "        traffic_signal = list(self.traffic_signals.values())[0]\n",
    "        print(traffic_signal.get_average_speed(), traffic_signal.get_total_queued(), traffic_signal._diff_waiting_time_reward(), traffic_signal.get_pressure())\n",
    "        reward = self.custom_reward(traffic_signal, reward_type='congesion', reward_method='simple')\n",
    "\n",
    "        self.state = next_state\n",
    "        self.done = terminated\n",
    "        return next_state, reward, self.done or truncated\n",
    "    \n",
    "    def render(self):\n",
    "        self.env.render()\n",
    "    \n",
    "    def close(self):\n",
    "        try:\n",
    "            self.env.close()\n",
    "            if traci.isLoaded():\n",
    "                traci.close()\n",
    "            print(\"Env and Traci closed successfully.\")\n",
    "        except Exception as e:\n",
    "            print(\"Error while closing the environment:\", e)\n",
    "    \n",
    "    def get_state(self):\n",
    "        return self.state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Agent Run Basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Environment (Simple Intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Space: 11\n",
      "Action Space: 2\n",
      "Initial State: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "action space Discrete(2)\n",
      "0.9705471392100999 0 0.0 -5\n",
      "Action  1  Reward  5  Done  False observation [1.         0.         0.         0.05048805 0.         0.10567101\n",
      " 0.10567101 0.         0.         0.         0.        ]\n",
      "0.8907290714368037 0 0.0 -9\n",
      "Action  1  Reward  9  Done  False observation [1.         0.         1.         0.1009761  0.05048805 0.15850651\n",
      " 0.15850651 0.         0.         0.         0.        ]\n",
      "0.7349946466997885 2 0.0 -14\n",
      "Action  0  Reward  14  Done  False observation [1.         0.         1.         0.15146415 0.15146415 0.21134202\n",
      " 0.21134202 0.         0.         0.05283551 0.05283551]\n",
      "0.64870672231928 1 0.0 -16\n",
      "Action  1  Reward  16  Done  False observation [0.         1.         0.         0.25244024 0.2019522  0.26417753\n",
      " 0.21134202 0.05048805 0.         0.         0.        ]\n",
      "0.5300957170042275 5 0.0 -9\n",
      "Action  0  Reward  9  Done  False observation [0.         1.         1.         0.25244024 0.2019522  0.10567101\n",
      " 0.21134202 0.15146415 0.1009761  0.         0.        ]\n",
      "0.31463480918785997 4 0.0 -6\n",
      "Action  0  Reward  6  Done  False observation [1.         0.         0.         0.25244024 0.2019522  0.10567101\n",
      " 0.15850651 0.05048805 0.05048805 0.05283551 0.05283551]\n",
      "0.5640174893624843 4 0.0 -6\n",
      "Action  0  Reward  6  Done  False observation [1.         0.         1.         0.2019522  0.15146415 0.21134202\n",
      " 0.21134202 0.         0.         0.10567101 0.10567101]\n",
      "0.5776559938188656 5 0.0 -3\n",
      "Action  0  Reward  3  Done  False observation [1.         0.         1.         0.05048805 0.1009761  0.26417753\n",
      " 0.26417753 0.         0.         0.10567101 0.15850651]\n",
      "0.35208033777820025 5 0.0 -5\n",
      "Action  0  Reward  5  Done  False observation [1.         0.         1.         0.05048805 0.05048805 0.26417753\n",
      " 0.31701303 0.         0.         0.10567101 0.15850651]\n",
      "0.2698792803992554 9 0.0 -10\n",
      "Action  0  Reward  10  Done  False observation [1.         0.         1.         0.05048805 0.         0.31701303\n",
      " 0.36984855 0.         0.         0.21134202 0.26417753]\n",
      "0.34430080340038977 11 0.0 -16\n",
      "Action  0  Reward  16  Done  False observation [1.         0.         1.         0.05048805 0.         0.47551954\n",
      " 0.47551954 0.         0.         0.26417753 0.31701303]\n",
      "0.2076833299338579 13 0.0 -19\n",
      "Action  0  Reward  19  Done  False observation [1.         0.         1.         0.         0.         0.52835506\n",
      " 0.5811906  0.         0.         0.31701303 0.36984855]\n",
      "0.12866620147635527 18 0.0 -23\n",
      "Action  0  Reward  23  Done  False observation [1.         0.         1.         0.         0.         0.63402605\n",
      " 0.63402605 0.         0.         0.42268404 0.52835506]\n",
      "0.13475219583620632 17 0.0 -23\n",
      "Action  1  Reward  23  Done  False observation [0.         1.         0.         0.         0.         0.63402605\n",
      " 0.6868616  0.         0.         0.42268404 0.47551954]\n",
      "0.23204559540867664 9 0.0 -19\n",
      "Action  1  Reward  19  Done  False observation [0.         1.         1.         0.05048805 0.         0.63402605\n",
      " 0.63402605 0.         0.         0.21134202 0.26417753]\n",
      "0.3390192900512525 4 0.0 -10\n",
      "Action  1  Reward  10  Done  False observation [0.         1.         1.         0.05048805 0.05048805 0.47551954\n",
      " 0.52835506 0.         0.         0.10567101 0.10567101]\n",
      "0.5535539152417982 0 0.0 -6\n",
      "Action  1  Reward  6  Done  False observation [0.         1.         1.         0.1009761  0.1009761  0.42268404\n",
      " 0.36984855 0.         0.         0.         0.        ]\n",
      "0.5100565748374044 2 0.0 -11\n",
      "Action  0  Reward  11  Done  False observation [1.         0.         0.         0.1009761  0.05048805 0.52835506\n",
      " 0.47551954 0.         0.         0.05283551 0.05283551]\n",
      "0.3335258511434238 8 0.0 -18\n",
      "Action  1  Reward  18  Done  False observation [1.         0.         1.         0.1009761  0.1009761  0.52835506\n",
      " 0.52835506 0.         0.         0.21134202 0.21134202]\n",
      "Keyboard interrupt detected. Closing the environment.\n",
      "Error while closing the environment: Connection closed by SUMO.\n"
     ]
    }
   ],
   "source": [
    "# Define paths to the network and route files (Buffalo Road Intersection)\n",
    "\n",
    "# net_file = 'C:/Users/ASUS/Sumo/2024-11-03-18-23-47/osm.net.xml/osm.net.xml'\n",
    "# route_file = 'C:/Users/ASUS/Sumo/2024-11-03-18-23-47/osm.passenger.rou.xml'\n",
    "# out_csv_name = 'C:/Users/ASUS/Sumo/2024-11-03-18-23-47/osm.passenger.csv'\n",
    "\n",
    "\n",
    "# Using Custom simple Traffic Intersection\n",
    "nets_dir = 'nets'\n",
    "\n",
    "file_name = 'single_intersection_simple'\n",
    "\n",
    "nets_file = os.path.join(nets_dir, f'{file_name}.net.xml')\n",
    "routes_file = os.path.join(nets_dir, f'{file_name}.rou.xml')\n",
    "\n",
    "file_exists = lambda file_path: os.path.exists(file_path)\n",
    "\n",
    "if not file_exists(nets_file):\n",
    "    raise FileNotFoundError(f\"Net file not found: {net_file}\")\n",
    "if not file_exists(routes_file):\n",
    "    raise FileNotFoundError(f\"Route file not found: {route_file}\")\n",
    "\n",
    "\n",
    "# Instantiate the environment\n",
    "sumo_env = Environment('sumo-rl-v0', net_file=nets_file, route_file=routes_file, out_csv_name=out_csv_name, render_mode=None)\n",
    "\n",
    "print(\"Observation Space:\", sumo_env.observation_space)\n",
    "print(\"Action Space:\", sumo_env.action_space.n)\n",
    "print(\"Initial State:\", sumo_env.state)\n",
    "\n",
    "max_steps = 1000\n",
    "\n",
    "try:\n",
    "    print(\"action space\", sumo_env.action_space)\n",
    "    for step in range(max_steps):\n",
    "        # sumo_env.render()\n",
    "        action = sumo_env.env.action_space.sample()\n",
    "        next_state, reward, done = sumo_env.step(action)\n",
    "        print(\"Action \", action, \" Reward \", reward, \" Done \", done, \"observation\", next_state)\n",
    "        \n",
    "        if done:\n",
    "            sumo_env.reset()\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Keyboard interrupt detected. Closing the environment.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error occurred:\", e)\n",
    "\n",
    "finally:\n",
    "    sumo_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up basic Neural Network for DQN\n",
    "from torch import nn\n",
    "\n",
    "input_nodes = 128\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, observation_size, action_size, input_nodes=128):\n",
    "        super(DQN, self).__init__()\n",
    "        print(\"Observation size Network\", observation_size)\n",
    "        print(\"Action size Network\", action_size)\n",
    "\n",
    "        self.fc1 = nn.Linear(observation_size, input_nodes)\n",
    "        self.fc2 = nn.Linear(input_nodes, input_nodes)\n",
    "        self.fc3 = nn.Linear(input_nodes, action_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for Replay Memory\n",
    "from collections import namedtuple, deque\n",
    "import random\n",
    "\n",
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward', 'done'))\n",
    "\n",
    "class ReplayMemory:\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the Agent Class for doing the DQN \n",
    "class Agent:\n",
    "    def __init__(self, env, epsilon, gamma, learning_rate, epsilon_decay, mem_size=5000):\n",
    "        self.env = env\n",
    "        self.state_size = env.observation_space\n",
    "        self.action_size = env.action_space.n\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = gamma\n",
    "        self.learning_rate = learning_rate\n",
    "        self.min_epsilon = 0.01\n",
    "        self.max_epsilon = 1\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "\n",
    "        self.memory_size_max = mem_size\n",
    "        self.memory_buffer = ReplayMemory(self.memory_size_max)\n",
    "        self.q_network = DQN(self.state_size, self.action_size)\n",
    "        self.q_target_network = DQN(self.state_size, self.action_size)\n",
    "        self.q_target_network.load_state_dict(self.q_network.state_dict())\n",
    "        self.loss_function = nn.MSELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.q_network.parameters(), lr=self.learning_rate)\n",
    "    \n",
    "    def choose_action(self, state):\n",
    "        if np.random.random() < self.epsilon:\n",
    "            return np.random.choice(self.action_size)\n",
    "        else:\n",
    "            state = torch.FloatTensor(state).unsqueeze(0)    \n",
    "            with torch.no_grad():\n",
    "                q_values = self.q_network(state)\n",
    "                return torch.argmax(q_values).item()\n",
    "    \n",
    "    def update_experience(self, state, action, reward, next_state, done):\n",
    "        state = torch.FloatTensor(state).unsqueeze(0)\n",
    "        next_state = torch.FloatTensor(next_state).unsqueeze(0)\n",
    "        action = torch.LongTensor([action]).view(-1, 1)\n",
    "        reward = torch.FloatTensor([reward]).to(torch.float32)\n",
    "        done = torch.FloatTensor([done]).to(torch.float32)\n",
    "        self.memory_buffer.push(state, action, next_state, reward, done)\n",
    "\n",
    "        if self.memory_buffer.__len__() > self.memory_size_max:\n",
    "            self.memory_buffer.pop(0)\n",
    "\n",
    "    def update_exploration_probability(self, episode):\n",
    "        self.epsilon = self.min_epsilon + (self.max_epsilon - self.min_epsilon) * np.exp(-self.epsilon_decay * episode)\n",
    "    \n",
    "    def optimize(self, batch_size):\n",
    "        if len(self.memory_buffer) < batch_size:\n",
    "            return\n",
    "\n",
    "        transitions = self.memory_buffer.sample(batch_size)\n",
    "        batch = Transition(*zip(*transitions))\n",
    "        \n",
    "        # Convert the parameters to torch tensors\n",
    "        # state_batch = torch.cat(batch.state)\n",
    "        # action_batch = torch.tensor(batch.action).view(-1, 1)\n",
    "        # reward_batch = torch.tensor(batch.reward).float()\n",
    "        # next_state_batch = torch.cat(batch.next_state)\n",
    "\n",
    "        state_batch = torch.cat(batch.state)\n",
    "        action_batch = torch.cat(batch.action)\n",
    "        reward_batch = torch.cat(batch.reward)\n",
    "        next_state_batch = torch.cat(batch.next_state)\n",
    "        done_batch = torch.cat(batch.done)\n",
    "\n",
    "        curr_q_vals = self.q_network(state_batch)\n",
    "        curr_q_vals = curr_q_vals.gather(1, action_batch)\n",
    "\n",
    "        # update target q value and current q values, backpropagate the loss\n",
    "        with torch.no_grad():\n",
    "            next_q_vals = self.q_target_network(next_state_batch)\n",
    "            max_next_q_vals = torch.max(next_q_vals, 1)[0]\n",
    "            target_q_vals = reward_batch + self.gamma * max_next_q_vals * (1 - done_batch)\n",
    "\n",
    "        loss = self.loss_function(curr_q_vals.squeeze(), target_q_vals)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # Handling the exploding gradient problem\n",
    "        nn.utils.clip_grad_norm_(self.q_network.parameters(), 1)\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item()\n",
    "    \n",
    "    def update_target_network(self):\n",
    "        self.q_target_network.load_state_dict(self.q_network.state_dict())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def trainer_dqn(env, agent, n_episodes, batch_size, epsilon, gamma, learning_rate, epsilon_decay, C):\n",
    "    max_steps = 500\n",
    "    use_wandb = os.environ.get('USE_WANDB', 'false').lower() == 'true'\n",
    "    epsilon_start = 1\n",
    "    epsilon_end = 0.01\n",
    "\n",
    "    if use_wandb:\n",
    "        wandb_config = {\n",
    "            'env': env.env_name,\n",
    "            'algorithm': 'DQN',\n",
    "            'batch_size': batch_size,\n",
    "            'gamma': gamma,\n",
    "            'eps_start': epsilon_start,\n",
    "            'eps_end': epsilon_end,\n",
    "            'eps_decay': epsilon_decay,\n",
    "            'target_update': C,\n",
    "            'lr': learning_rate,\n",
    "            'num_episodes': n_episodes,\n",
    "            'max_timesteps': max_steps,\n",
    "            'seed': 0\n",
    "        }\n",
    "        \n",
    "        cust_wandb = WanDB(wandb_config, f'assignment-2-{env.env_name}', env.env_name)\n",
    "       \n",
    "    \n",
    "    loss_list = []\n",
    "    reward_list = []\n",
    "    rewards_per_episode = {}\n",
    "    epsilon_values = []\n",
    "\n",
    "    p_bar = tqdm(range(n_episodes), colour='green', desc='Training progress', unit='Episode')\n",
    "    \n",
    "\n",
    "    tot_steps = 0\n",
    "\n",
    "    try:\n",
    "        for episode in p_bar:\n",
    "            state = env.reset()\n",
    "            done = False\n",
    "            total_reward = 0\n",
    "            total_loss = 0            \n",
    "    \n",
    "            for step_ in range(max_steps):\n",
    "                    tot_steps += 1\n",
    "                    action = agent.choose_action(state)\n",
    "                    print(\"Action \", action)\n",
    "                    next_state, reward, done = env.step(action)\n",
    "\n",
    "                    print(\"Action \", action, \" Reward \", reward, \" Done \", done, \"observation\", next_state)\n",
    "                    # Save the transition in the replay memory\n",
    "                    agent.update_experience(state, action, reward, next_state, done)\n",
    "\n",
    "                    # Run the optimization step\n",
    "                    loss = agent.optimize(batch_size)\n",
    "                    if loss:\n",
    "                        if use_wandb:\n",
    "                            cust_wandb.wandb_log({\n",
    "                                    'loss': loss, \n",
    "                                    'step_reward': reward, \n",
    "                                    'step': tot_steps\n",
    "                                })\n",
    "                        \n",
    "                        total_loss += loss\n",
    "                    total_reward += reward\n",
    "                    state = next_state\n",
    "\n",
    "                    if done:\n",
    "                        break\n",
    "\n",
    "                    if episode % C == 0:\n",
    "                        agent.update_target_network()\n",
    "\n",
    "            agent.update_exploration_probability(episode)\n",
    "            epsilon_values.append(agent.epsilon)\n",
    "\n",
    "            loss_list.append(total_loss)\n",
    "            reward_list.append(total_reward)\n",
    "            rewards_per_episode[episode] = total_reward\n",
    "\n",
    "            if use_wandb:\n",
    "                cust_wandb.wandb_log({\n",
    "                            'epsilon': agent.epsilon,\n",
    "                            'total_reward': total_reward,\n",
    "                            'epsilon': agent.epsilon,\n",
    "                            'total_loss': total_loss,\n",
    "                            'episode': episode\n",
    "                })\n",
    "    except traci.exceptions.FatalTraCIError as e:\n",
    "        print(\"TraCI error:\", e)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Keyboard interrupt detected. Closing the environment.\")\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred in episode {episode}, step {step_}: {e}\")\n",
    "        raise\n",
    "\n",
    "        \n",
    "    finally:\n",
    "        if use_wandb:\n",
    "            cust_wandb.wandb_finish()\n",
    "            print(f'Episode: {episode}, Total Reward: {total_reward}, Loss: {total_loss}')\n",
    "    env.close()        \n",
    "    return reward_list, loss_list, rewards_per_episode, epsilon_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.traffic_signals to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.traffic_signals` for environment variables or `env.get_wrapper_attr('traffic_signals')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Space: 11\n",
      "Action Space: Discrete(2)\n",
      "Observation size Network 11\n",
      "Action size Network 2\n",
      "Observation size Network 11\n",
      "Action size Network 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   0%|\u001b[32m          \u001b[0m| 0/1000 [00:00<?, ?Episode/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action space Discrete(2) 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   0%|\u001b[32m          \u001b[0m| 0/1000 [00:00<?, ?Episode/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TraCI error: Connection already closed.\n",
      "Env and Traci closed successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Trainer method\n",
    "\n",
    "n_episodes = 1000\n",
    "batch_size = 64\n",
    "epsilon = 1\n",
    "gamma = 0.99\n",
    "learning_rate = 1e-3\n",
    "epsilon_decay = 0.995\n",
    "C = 5\n",
    "\n",
    "nets_dir = 'nets'\n",
    "\n",
    "file_name = 'single_intersection_simple'\n",
    "\n",
    "nets_file = os.path.join(nets_dir, f'{file_name}.net.xml')\n",
    "routes_file = os.path.join(nets_dir, f'{file_name}.rou.xml')\n",
    "\n",
    "file_exists = lambda file_path: os.path.exists(file_path)\n",
    "\n",
    "if not file_exists(nets_file):\n",
    "    raise FileNotFoundError(f\"Net file not found: {net_file}\")\n",
    "if not file_exists(routes_file):\n",
    "    raise FileNotFoundError(f\"Route file not found: {route_file}\")\n",
    "\n",
    "sumo_env = Environment('sumo-rl-v0', net_file=nets_file, route_file=routes_file, out_csv_name=out_csv_name, render_mode=None, num_seconds=1000)\n",
    "\n",
    "\n",
    "print(\"Observation Space:\", sumo_env.observation_space)\n",
    "print(\"Action Space:\", sumo_env.action_space)\n",
    "# print(\"Initial State:\", sumo_env.state)\n",
    "\n",
    "agent = Agent(sumo_env, epsilon, gamma, learning_rate, epsilon_decay)\n",
    "\n",
    "\n",
    "rewards, losses, rewards_per_episode, epsilon_values = trainer_dqn(sumo_env, agent, n_episodes, batch_size, epsilon, gamma, learning_rate, epsilon_decay, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training A3C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrying in 1 seconds\n",
      "Observation Space: 11\n",
      "Action Space: Discrete(2)\n",
      "Initial State: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Training started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.traffic_signals to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.traffic_signals` for environment variables or `env.get_wrapper_attr('traffic_signals')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot pickle '_thread.lock' object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m actions \u001b[38;5;241m=\u001b[39m sumo_env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mn\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# train_a3c(sumo_env, max_steps=1000, num_episodes=10, gamma=0.99, lr=0.001, beta=0.01, num_processes=4)\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[43mtrain_a3c\u001b[49m\u001b[43m(\u001b[49m\u001b[43msumo_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43minput_dims\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_actions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_wandb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_clip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSUMO-RL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\RL_Project\\ReinforcementLearning_FinalCourseProject\\a3c_cartpole.py:261\u001b[0m, in \u001b[0;36mtrain_a3c\u001b[1;34m(env, env_id, input_dims, n_actions, n_episodes, gamma, use_wandb, grad_clip, C, lr)\u001b[0m\n\u001b[0;32m    252\u001b[0m rewards_list \u001b[38;5;241m=\u001b[39m thread_manager\u001b[38;5;241m.\u001b[39mlist()\n\u001b[0;32m    254\u001b[0m workers \u001b[38;5;241m=\u001b[39m [Agent(global_actor_critic, optim, input_dims, n_actions, gamma,\n\u001b[0;32m    255\u001b[0m                  lr, i,\n\u001b[0;32m    256\u001b[0m                  global_ep_idx\u001b[38;5;241m=\u001b[39mglobal_ep,\n\u001b[0;32m    257\u001b[0m                  env_id\u001b[38;5;241m=\u001b[39menv_id,\n\u001b[0;32m    258\u001b[0m                  env\u001b[38;5;241m=\u001b[39menv,\n\u001b[0;32m    259\u001b[0m                  n_episodes\u001b[38;5;241m=\u001b[39mn_episodes, rewards_list\u001b[38;5;241m=\u001b[39mrewards_list, grad_clip\u001b[38;5;241m=\u001b[39mgrad_clip, C\u001b[38;5;241m=\u001b[39mC) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(mp\u001b[38;5;241m.\u001b[39mcpu_count())]\n\u001b[1;32m--> 261\u001b[0m [w\u001b[38;5;241m.\u001b[39mstart() \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m workers]\n\u001b[0;32m    262\u001b[0m [w\u001b[38;5;241m.\u001b[39mjoin() \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m workers]\n\u001b[0;32m    265\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma3c_models\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32md:\\RL_Project\\ReinforcementLearning_FinalCourseProject\\a3c_cartpole.py:261\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    252\u001b[0m rewards_list \u001b[38;5;241m=\u001b[39m thread_manager\u001b[38;5;241m.\u001b[39mlist()\n\u001b[0;32m    254\u001b[0m workers \u001b[38;5;241m=\u001b[39m [Agent(global_actor_critic, optim, input_dims, n_actions, gamma,\n\u001b[0;32m    255\u001b[0m                  lr, i,\n\u001b[0;32m    256\u001b[0m                  global_ep_idx\u001b[38;5;241m=\u001b[39mglobal_ep,\n\u001b[0;32m    257\u001b[0m                  env_id\u001b[38;5;241m=\u001b[39menv_id,\n\u001b[0;32m    258\u001b[0m                  env\u001b[38;5;241m=\u001b[39menv,\n\u001b[0;32m    259\u001b[0m                  n_episodes\u001b[38;5;241m=\u001b[39mn_episodes, rewards_list\u001b[38;5;241m=\u001b[39mrewards_list, grad_clip\u001b[38;5;241m=\u001b[39mgrad_clip, C\u001b[38;5;241m=\u001b[39mC) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(mp\u001b[38;5;241m.\u001b[39mcpu_count())]\n\u001b[1;32m--> 261\u001b[0m [\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m workers]\n\u001b[0;32m    262\u001b[0m [w\u001b[38;5;241m.\u001b[39mjoin() \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m workers]\n\u001b[0;32m    265\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma3c_models\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot pickle '_thread.lock' object"
     ]
    }
   ],
   "source": [
    "from a3c_cartpole import train_a3c\n",
    "\n",
    "nets_dir = 'nets'\n",
    "\n",
    "file_name = 'single_intersection_simple'\n",
    "\n",
    "nets_file = os.path.join(nets_dir, f'{file_name}.net.xml')\n",
    "routes_file = os.path.join(nets_dir, f'{file_name}.rou.xml')\n",
    "sumo_env = Environment('sumo-rl-v0', net_file=nets_file, route_file=routes_file, out_csv_name=out_csv_name)\n",
    "\n",
    "print(\"Observation Space:\", sumo_env.observation_space)\n",
    "print(\"Action Space:\", sumo_env.action_space)\n",
    "print(\"Initial State:\", sumo_env.state)\n",
    "\n",
    "max_steps = 1000\n",
    "\n",
    "input_dims = sumo_env.observation_space\n",
    "actions = sumo_env.action_space.n\n",
    "# Train the model\n",
    "# train_a3c(sumo_env, max_steps=1000, num_episodes=10, gamma=0.99, lr=0.001, beta=0.01, num_processes=4)\n",
    "train_a3c(sumo_env, input_dims=[input_dims], n_actions=actions, n_episodes=1000, use_wandb=False, grad_clip=1, C=10, env_id='SUMO-RL', lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msumo_rl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SumoEnvironment\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Print SUMO_HOME for confirmation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sumo_rl\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Import all the necessary modules for the sumo_rl package.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msumo_rl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvironment\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      4\u001b[0m     ObservationFunction,\n\u001b[0;32m      5\u001b[0m     SumoEnvironment,\n\u001b[0;32m      6\u001b[0m     TrafficSignal,\n\u001b[0;32m      7\u001b[0m     env,\n\u001b[0;32m      8\u001b[0m     parallel_env,\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msumo_rl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvironment\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresco_envs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     arterial4x4,\n\u001b[0;32m     12\u001b[0m     cologne1,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     ingolstadt21,\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     22\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.4.5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sumo_rl\\environment\\env.py:15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msumolib\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraci\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\__init__.py:134\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m offsets\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomputation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28meval\u001b[39m\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    135\u001b[0m     concat,\n\u001b[0;32m    136\u001b[0m     lreshape,\n\u001b[0;32m    137\u001b[0m     melt,\n\u001b[0;32m    138\u001b[0m     wide_to_long,\n\u001b[0;32m    139\u001b[0m     merge,\n\u001b[0;32m    140\u001b[0m     merge_asof,\n\u001b[0;32m    141\u001b[0m     merge_ordered,\n\u001b[0;32m    142\u001b[0m     crosstab,\n\u001b[0;32m    143\u001b[0m     pivot,\n\u001b[0;32m    144\u001b[0m     pivot_table,\n\u001b[0;32m    145\u001b[0m     get_dummies,\n\u001b[0;32m    146\u001b[0m     from_dummies,\n\u001b[0;32m    147\u001b[0m     cut,\n\u001b[0;32m    148\u001b[0m     qcut,\n\u001b[0;32m    149\u001b[0m )\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api, arrays, errors, io, plotting, tseries\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m testing\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\api.py:16\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmelt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     lreshape,\n\u001b[0;32m      8\u001b[0m     melt,\n\u001b[0;32m      9\u001b[0m     wide_to_long,\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     12\u001b[0m     merge,\n\u001b[0;32m     13\u001b[0m     merge_asof,\n\u001b[0;32m     14\u001b[0m     merge_ordered,\n\u001b[0;32m     15\u001b[0m )\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpivot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     17\u001b[0m     crosstab,\n\u001b[0;32m     18\u001b[0m     pivot,\n\u001b[0;32m     19\u001b[0m     pivot_table,\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     22\u001b[0m     cut,\n\u001b[0;32m     23\u001b[0m     qcut,\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     26\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconcat\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcrosstab\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwide_to_long\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     41\u001b[0m ]\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:879\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:975\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1074\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from sumo_rl import SumoEnvironment\n",
    "import os\n",
    "\n",
    "# Print SUMO_HOME for confirmation\n",
    "print(\"SUMO_HOME is set to:\", os.environ['SUMO_HOME'])\n",
    "\n",
    "# Initialize SUMO Gym environment\n",
    "env = gym.make(\n",
    "    'sumo-rl-v0',\n",
    "    net_file=net_file,\n",
    "    route_file=route_file,\n",
    "    out_csv_name=out_csv_name,\n",
    "    use_gui=True,\n",
    "    num_seconds=100000\n",
    ")\n",
    "\n",
    "# Reset the environment and start simulation\n",
    "obs, info = env.reset()\n",
    "done = False\n",
    "\n",
    "print(env.action_space)\n",
    "\n",
    "while not done:\n",
    "    next_obs, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "    print(\"Reward:\", reward)\n",
    "    print(\"Observation:\", next_obs)\n",
    "    done = terminated or truncated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge IDs: ['n_t', 't_e', 't_s', 'w_t']\n",
      "Traffic Light IDs: ['t']\n"
     ]
    }
   ],
   "source": [
    "import sumolib\n",
    "\n",
    "# Load the network file\n",
    "net = sumolib.net.readNet(nets_file)  # Replace with your network file\n",
    "\n",
    "# Get all edge IDs\n",
    "edge_ids = [edge.getID() for edge in net.getEdges()]\n",
    "print(\"Edge IDs:\", edge_ids)\n",
    "\n",
    "# List all traffic light IDs\n",
    "tls_ids = [tls.getID() for tls in net.getTrafficLights()]\n",
    "print(\"Traffic Light IDs:\", tls_ids)\n",
    "\n",
    "# # Get all vehicle IDs in the current step\n",
    "# vehicle_ids = traci.vehicle.getIDList()\n",
    "# print(\"Vehicle IDs:\", vehicle_ids)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrying in 1 seconds\n",
      "TraCI connected successfully.\n",
      "Step 0, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 1, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 2, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 3, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 4, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 5, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 6, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 7, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 8, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 9, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 10, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 11, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 12, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 13, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 14, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 15, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 16, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 17, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 18, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 19, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 20, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 21, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 22, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 23, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 24, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 25, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 26, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 27, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 28, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 29, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 30, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 31, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 32, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 33, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 34, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 35, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 36, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 37, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 38, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 39, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 40, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 41, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 42, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 1\n",
      "Step 43, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 1\n",
      "Step 44, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 2\n",
      "Step 45, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 2\n",
      "Step 46, Vehicle count on t_e: 2\n",
      "Traffic light t phase: 2\n",
      "Step 47, Vehicle count on t_e: 2\n",
      "Traffic light t phase: 2\n",
      "Step 48, Vehicle count on t_e: 2\n",
      "Traffic light t phase: 2\n",
      "Step 49, Vehicle count on t_e: 4\n",
      "Traffic light t phase: 2\n",
      "Step 50, Vehicle count on t_e: 4\n",
      "Traffic light t phase: 2\n",
      "Step 51, Vehicle count on t_e: 6\n",
      "Traffic light t phase: 2\n",
      "Step 52, Vehicle count on t_e: 6\n",
      "Traffic light t phase: 2\n",
      "Step 53, Vehicle count on t_e: 8\n",
      "Traffic light t phase: 2\n",
      "Step 54, Vehicle count on t_e: 8\n",
      "Traffic light t phase: 2\n",
      "Step 55, Vehicle count on t_e: 10\n",
      "Traffic light t phase: 2\n",
      "Step 56, Vehicle count on t_e: 10\n",
      "Traffic light t phase: 2\n",
      "Step 57, Vehicle count on t_e: 12\n",
      "Traffic light t phase: 2\n",
      "Step 58, Vehicle count on t_e: 11\n",
      "Traffic light t phase: 2\n",
      "Step 59, Vehicle count on t_e: 12\n",
      "Traffic light t phase: 2\n",
      "Step 60, Vehicle count on t_e: 12\n",
      "Traffic light t phase: 2\n",
      "Step 61, Vehicle count on t_e: 13\n",
      "Traffic light t phase: 2\n",
      "Step 62, Vehicle count on t_e: 12\n",
      "Traffic light t phase: 2\n",
      "Step 63, Vehicle count on t_e: 13\n",
      "Traffic light t phase: 2\n",
      "Step 64, Vehicle count on t_e: 13\n",
      "Traffic light t phase: 2\n",
      "Step 65, Vehicle count on t_e: 14\n",
      "Traffic light t phase: 2\n",
      "Step 66, Vehicle count on t_e: 12\n",
      "Traffic light t phase: 2\n",
      "Step 67, Vehicle count on t_e: 14\n",
      "Traffic light t phase: 2\n",
      "Step 68, Vehicle count on t_e: 13\n",
      "Traffic light t phase: 2\n",
      "Step 69, Vehicle count on t_e: 14\n",
      "Traffic light t phase: 2\n",
      "Step 70, Vehicle count on t_e: 13\n",
      "Traffic light t phase: 2\n",
      "Step 71, Vehicle count on t_e: 13\n",
      "Traffic light t phase: 2\n",
      "Step 72, Vehicle count on t_e: 14\n",
      "Traffic light t phase: 2\n",
      "Step 73, Vehicle count on t_e: 13\n",
      "Traffic light t phase: 2\n",
      "Step 74, Vehicle count on t_e: 14\n",
      "Traffic light t phase: 2\n",
      "Step 75, Vehicle count on t_e: 13\n",
      "Traffic light t phase: 2\n",
      "Step 76, Vehicle count on t_e: 14\n",
      "Traffic light t phase: 2\n",
      "Step 77, Vehicle count on t_e: 13\n",
      "Traffic light t phase: 2\n",
      "Step 78, Vehicle count on t_e: 13\n",
      "Traffic light t phase: 2\n",
      "Step 79, Vehicle count on t_e: 13\n",
      "Traffic light t phase: 2\n",
      "Step 80, Vehicle count on t_e: 12\n",
      "Traffic light t phase: 2\n",
      "Step 81, Vehicle count on t_e: 12\n",
      "Traffic light t phase: 2\n",
      "Step 82, Vehicle count on t_e: 12\n",
      "Traffic light t phase: 2\n",
      "Step 83, Vehicle count on t_e: 12\n",
      "Traffic light t phase: 2\n",
      "Step 84, Vehicle count on t_e: 11\n",
      "Traffic light t phase: 2\n",
      "Step 85, Vehicle count on t_e: 11\n",
      "Traffic light t phase: 2\n",
      "Step 86, Vehicle count on t_e: 10\n",
      "Traffic light t phase: 3\n",
      "Step 87, Vehicle count on t_e: 10\n",
      "Traffic light t phase: 3\n",
      "Step 88, Vehicle count on t_e: 9\n",
      "Traffic light t phase: 0\n",
      "Step 89, Vehicle count on t_e: 8\n",
      "Traffic light t phase: 0\n",
      "Step 90, Vehicle count on t_e: 8\n",
      "Traffic light t phase: 0\n",
      "Step 91, Vehicle count on t_e: 7\n",
      "Traffic light t phase: 0\n",
      "Step 92, Vehicle count on t_e: 6\n",
      "Traffic light t phase: 0\n",
      "Step 93, Vehicle count on t_e: 6\n",
      "Traffic light t phase: 0\n",
      "Step 94, Vehicle count on t_e: 4\n",
      "Traffic light t phase: 0\n",
      "Step 95, Vehicle count on t_e: 2\n",
      "Traffic light t phase: 0\n",
      "Step 96, Vehicle count on t_e: 2\n",
      "Traffic light t phase: 0\n",
      "Step 97, Vehicle count on t_e: 1\n",
      "Traffic light t phase: 0\n",
      "Step 98, Vehicle count on t_e: 1\n",
      "Traffic light t phase: 0\n",
      "Step 99, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 100, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 101, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 102, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 103, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 104, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 105, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 106, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 107, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 108, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 109, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 110, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 111, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 112, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 113, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 114, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 115, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 116, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 117, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 118, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 119, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 120, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 121, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 122, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 123, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 124, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 125, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 126, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 127, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 128, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 129, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 130, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 1\n",
      "Step 131, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 1\n",
      "Step 132, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 2\n",
      "Step 133, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 2\n",
      "Step 134, Vehicle count on t_e: 2\n",
      "Traffic light t phase: 2\n",
      "Step 135, Vehicle count on t_e: 2\n",
      "Traffic light t phase: 2\n",
      "Step 136, Vehicle count on t_e: 2\n",
      "Traffic light t phase: 2\n",
      "Step 137, Vehicle count on t_e: 4\n",
      "Traffic light t phase: 2\n",
      "Step 138, Vehicle count on t_e: 4\n",
      "Traffic light t phase: 2\n",
      "Step 139, Vehicle count on t_e: 6\n",
      "Traffic light t phase: 2\n",
      "Step 140, Vehicle count on t_e: 6\n",
      "Traffic light t phase: 2\n",
      "Step 141, Vehicle count on t_e: 8\n",
      "Traffic light t phase: 2\n",
      "Step 142, Vehicle count on t_e: 8\n",
      "Traffic light t phase: 2\n",
      "Step 143, Vehicle count on t_e: 10\n",
      "Traffic light t phase: 2\n",
      "Step 144, Vehicle count on t_e: 10\n",
      "Traffic light t phase: 2\n",
      "Step 145, Vehicle count on t_e: 11\n",
      "Traffic light t phase: 2\n",
      "Step 146, Vehicle count on t_e: 11\n",
      "Traffic light t phase: 2\n",
      "Step 147, Vehicle count on t_e: 12\n",
      "Traffic light t phase: 2\n",
      "Step 148, Vehicle count on t_e: 11\n",
      "Traffic light t phase: 2\n",
      "Step 149, Vehicle count on t_e: 12\n",
      "Traffic light t phase: 2\n",
      "Step 150, Vehicle count on t_e: 14\n",
      "Traffic light t phase: 2\n",
      "Step 151, Vehicle count on t_e: 13\n",
      "Traffic light t phase: 2\n",
      "Step 152, Vehicle count on t_e: 14\n",
      "Traffic light t phase: 2\n",
      "Step 153, Vehicle count on t_e: 12\n",
      "Traffic light t phase: 2\n",
      "Step 154, Vehicle count on t_e: 14\n",
      "Traffic light t phase: 2\n",
      "Step 155, Vehicle count on t_e: 12\n",
      "Traffic light t phase: 2\n",
      "Step 156, Vehicle count on t_e: 14\n",
      "Traffic light t phase: 2\n",
      "Step 157, Vehicle count on t_e: 12\n",
      "Traffic light t phase: 2\n",
      "Step 158, Vehicle count on t_e: 14\n",
      "Traffic light t phase: 2\n",
      "Step 159, Vehicle count on t_e: 13\n",
      "Traffic light t phase: 2\n",
      "Step 160, Vehicle count on t_e: 13\n",
      "Traffic light t phase: 2\n",
      "Step 161, Vehicle count on t_e: 12\n",
      "Traffic light t phase: 2\n",
      "Step 162, Vehicle count on t_e: 12\n",
      "Traffic light t phase: 2\n",
      "Step 163, Vehicle count on t_e: 12\n",
      "Traffic light t phase: 2\n",
      "Step 164, Vehicle count on t_e: 12\n",
      "Traffic light t phase: 2\n",
      "Step 165, Vehicle count on t_e: 12\n",
      "Traffic light t phase: 2\n",
      "Step 166, Vehicle count on t_e: 12\n",
      "Traffic light t phase: 2\n",
      "Step 167, Vehicle count on t_e: 11\n",
      "Traffic light t phase: 2\n",
      "Step 168, Vehicle count on t_e: 12\n",
      "Traffic light t phase: 2\n",
      "Step 169, Vehicle count on t_e: 11\n",
      "Traffic light t phase: 2\n",
      "Step 170, Vehicle count on t_e: 12\n",
      "Traffic light t phase: 2\n",
      "Step 171, Vehicle count on t_e: 13\n",
      "Traffic light t phase: 2\n",
      "Step 172, Vehicle count on t_e: 13\n",
      "Traffic light t phase: 2\n",
      "Step 173, Vehicle count on t_e: 12\n",
      "Traffic light t phase: 2\n",
      "Step 174, Vehicle count on t_e: 14\n",
      "Traffic light t phase: 3\n",
      "Step 175, Vehicle count on t_e: 14\n",
      "Traffic light t phase: 3\n",
      "Step 176, Vehicle count on t_e: 13\n",
      "Traffic light t phase: 0\n",
      "Step 177, Vehicle count on t_e: 11\n",
      "Traffic light t phase: 0\n",
      "Step 178, Vehicle count on t_e: 11\n",
      "Traffic light t phase: 0\n",
      "Step 179, Vehicle count on t_e: 9\n",
      "Traffic light t phase: 0\n",
      "Step 180, Vehicle count on t_e: 8\n",
      "Traffic light t phase: 0\n",
      "Step 181, Vehicle count on t_e: 7\n",
      "Traffic light t phase: 0\n",
      "Step 182, Vehicle count on t_e: 6\n",
      "Traffic light t phase: 0\n",
      "Step 183, Vehicle count on t_e: 5\n",
      "Traffic light t phase: 0\n",
      "Step 184, Vehicle count on t_e: 4\n",
      "Traffic light t phase: 0\n",
      "Step 185, Vehicle count on t_e: 3\n",
      "Traffic light t phase: 0\n",
      "Step 186, Vehicle count on t_e: 1\n",
      "Traffic light t phase: 0\n",
      "Step 187, Vehicle count on t_e: 1\n",
      "Traffic light t phase: 0\n",
      "Step 188, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 189, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 190, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 191, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 192, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 193, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 194, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 195, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 196, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 197, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 198, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 199, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 200, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 201, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 202, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 203, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 204, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 205, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 206, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 207, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 208, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 209, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 210, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 211, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 212, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 213, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 214, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "Step 215, Vehicle count on t_e: 0\n",
      "Traffic light t phase: 0\n",
      "\n",
      "Simulation interrupted by user.\n"
     ]
    },
    {
     "ename": "FatalTraCIError",
     "evalue": "Connection closed by SUMO.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFatalTraCIError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 63\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m traci\u001b[38;5;241m.\u001b[39misLoaded():\n\u001b[1;32m---> 63\u001b[0m         \u001b[43mtraci\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraCI connection closed safely.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m traci\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mTraCIException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\traci\\main.py:262\u001b[0m, in \u001b[0;36mclose\u001b[1;34m(wait)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclose\u001b[39m(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    259\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;124;03m    Tells TraCI to close the connection.\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 262\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\traci\\connection.py:397\u001b[0m, in \u001b[0;36mConnection.close\u001b[1;34m(self, wait)\u001b[0m\n\u001b[0;32m    395\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremoveStepListener(listenerID)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_socket \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendCmd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCMD_CLOSE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_socket\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_socket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\traci\\connection.py:232\u001b[0m, in \u001b[0;36mConnection._sendCmd\u001b[1;34m(self, cmdID, varID, objID, format, *values)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_string \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(objID)) \u001b[38;5;241m+\u001b[39m objID\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_string \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m packed\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendExact\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\traci\\connection.py:137\u001b[0m, in \u001b[0;36mConnection._sendExact\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_socket\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_socket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FatalTraCIError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection closed by SUMO.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m command \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue:\n\u001b[0;32m    139\u001b[0m     prefix \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!BBB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFatalTraCIError\u001b[0m: Connection closed by SUMO."
     ]
    }
   ],
   "source": [
    "import traci\n",
    "import sumolib\n",
    "import sys\n",
    "import time\n",
    "\n",
    "try:\n",
    "    # Define paths to SUMO binary, network file, and route file\n",
    "    sumo_binary = \"sumo-gui\"  # Use \"sumo\" for non-GUI mode\n",
    "    # Command to start SUMO with TraCI connection\n",
    "    sumo_cmd = [sumo_binary, \"-n\", nets_file, \"-r\", routes_file, \"--start\"]\n",
    "    \n",
    "    # Attempt to start SUMO with the specified command\n",
    "    try:\n",
    "        traci.start(sumo_cmd, label=\"sim1\")\n",
    "    except traci.exceptions.TraCIException as e:\n",
    "        print(f\"Failed to start TraCI: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(\"TraCI connected successfully.\")\n",
    "    \n",
    "    # Main simulation loop with safe TraCI operations\n",
    "    for step in range(1000):\n",
    "        try:\n",
    "            traci.simulationStep()  # Advance simulation by one step\n",
    "            \n",
    "            # Check vehicle count on a specific edge\n",
    "            edge_id = \"t_e\"  # Replace with actual edge ID\n",
    "            try:\n",
    "                vehicle_count = traci.edge.getLastStepVehicleNumber(edge_id)\n",
    "                print(f\"Step {step}, Vehicle count on {edge_id}: {vehicle_count}\")\n",
    "            except traci.exceptions.TraCIException as e:\n",
    "                print(f\"Error retrieving vehicle count for edge {edge_id}: {e}\")\n",
    "            \n",
    "            # Get traffic light phase and queue length\n",
    "            tls_id = \"t\"  # Replace with actual traffic light ID\n",
    "            try:\n",
    "                phase = traci.trafficlight.getPhase(tls_id)\n",
    "                print(f\"Traffic light {tls_id} phase: {phase}\")\n",
    "            except traci.exceptions.TraCIException as e:\n",
    "                print(f\"Error retrieving traffic light phase for {tls_id}: {e}\")\n",
    "            \n",
    "            # Pause to inspect values for each step\n",
    "            # input(\"Press Enter to continue to the next step...\")\n",
    "            time.sleep(0.5)\n",
    "            \n",
    "            if step >= max_steps -1:\n",
    "                break            \n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nSimulation interrupted by user.\")\n",
    "            break  # Safely exit the loop if user interrupts\n",
    "\n",
    "except (FileNotFoundError, traci.exceptions.TraCIException) as e:\n",
    "    print(f\"Error in setup or simulation: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Ensure that TraCI closes safely even if an error occurs\n",
    "    try:\n",
    "        if traci.isLoaded():\n",
    "            traci.close()\n",
    "            print(\"TraCI connection closed safely.\")\n",
    "    except traci.exceptions.TraCIException as e:\n",
    "        print(f\"Error while closing TraCI: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
